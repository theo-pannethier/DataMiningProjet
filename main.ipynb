{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fda1921-2fa4-41f0-b23b-d8f45265f8dc",
   "metadata": {},
   "source": [
    "# Projet de DataMining :  \n",
    "\n",
    "Dans ce projet nous allons recommander des images en fonctions d'images déjà \"liké\".\n",
    "Pour cela nous avons commencé par traiter une base de 733 images en recupérant le maximun de données. On recupére notament les données Exif, la taille de l'image, son orientation, ect ...  \n",
    "La base de données d'images vient du lien suivant:\n",
    "https://www.kaggle.com/aksha05/flower-image-dataset\n",
    "## Requirements : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480f5202-5367-4a3d-a3b6-d640fb51efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "import time\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import graphviz\n",
    "import pydotplus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c5227-4af1-432b-afc3-b873b7fdb8a9",
   "metadata": {},
   "source": [
    "## Récupération des données et organisation de ces données dans un fichier json:  \n",
    "\n",
    "\n",
    " Ce code est passé en Markdown pour ne pas qu'il soit relancé et déteriore le data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1fbe29",
   "metadata": {
    "vscode": {
     "languageId": "json"
    }
   },
   "source": [
    "``` python\n",
    "path = \"images/flowers\"\n",
    "dataJson = open('data.json', 'w')\n",
    "dataTot = []\n",
    "for file in os.listdir(path): #On peut lire l'ensemble des fichiers présents dans le dossier donné par path\n",
    "    data = {}\n",
    "    if file[0] != \".\": #On exclue les fichiers \"cachés\"\n",
    "        new_path = path + \"/\" + file\n",
    "        image = Image.open(new_path) #Récupération de l'image avec le module Image de PIL\n",
    "        tupleSize = image.size\n",
    "        data[\"id_picture\"] = file[-9:-4]\n",
    "        data[\"name\"] = file[:-10]\n",
    "        data[\"size\"] = tupleSize\n",
    "        data[\"format\"] = image.format\n",
    "        data[\"couleur 1\"] = ''\n",
    "        data[\"couleur 2\"] = ''\n",
    "        data[\"couleur 3\"] = ''\n",
    "        data[\"couleur 4\"] = ''\n",
    "        if tupleSize[0] > tupleSize[1] : \n",
    "            data[\"orientation\"] = \"paysage\"\n",
    "        elif tupleSize[0] < tupleSize[1] :\n",
    "            data[\"orientation\"] = \"portrait\"\n",
    "        else:\n",
    "            data[\"orientation\"] = \"carre\"\n",
    "        dataTot.append(data)\n",
    "\n",
    "json.dump(dataTot,dataJson, indent = 4)\n",
    "dataJson.close()\n",
    "dataTot_frame = json_normalize(dataTot)\n",
    "print(dataTot_frame)\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414d65a-03ad-40e5-99cd-049df06c8011",
   "metadata": {},
   "source": [
    "## Détection des couleurs prédominantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7442a2",
   "metadata": {},
   "source": [
    "On isole les 4 couleurs prédominates avec l'algorithme **KMeans**. Ceci nous premettra de les faire correspondre à des couleurs de réference qui permetteront d'aggrémenter notre fichier data.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167fa0cc-a34e-4ee8-8eba-c196a09d09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "imgfile = Image.open(\"images/flowers/daisies_00046.jpg\")\n",
    "n_clusters = 4 #int(input(\"Nombre de clusters pour l'algorithme des K-Means: \"))\n",
    "numarray = numpy.array(imgfile.getdata(), numpy.uint8)\n",
    "clusters = KMeans(n_clusters)\n",
    "clusters.fit(numarray)\n",
    "npbins = numpy.arange(0, n_clusters+1)\n",
    "histogram = numpy.histogram(clusters.labels_, bins=npbins)\n",
    "labels = numpy.unique(clusters.labels_)\n",
    "index1 = {}\n",
    "for i,element in enumerate(histogram[0]):\n",
    "    index1[element] = i\n",
    "#print(index1)\n",
    "histoSort = sorted(histogram[0], reverse=True)\n",
    "#print(histoSort)\n",
    "index2 = {}\n",
    "for i,element in enumerate(histoSort):\n",
    "    index2[i] = element\n",
    "#print(index2)\n",
    "barlist = plot.bar(labels, histoSort)\n",
    "colors = []\n",
    "for k in range(n_clusters):\n",
    "    i = index1[index2[k]]\n",
    "    colors.append('#%02x%02x%02x' % (\n",
    "    math.ceil(clusters.cluster_centers_[i][0]), \n",
    "        math.ceil(clusters.cluster_centers_[i][1]),\n",
    "    math.ceil(clusters.cluster_centers_[i][2])))\n",
    "    barlist[k].set_color('#%02x%02x%02x' % (\n",
    "    math.ceil(clusters.cluster_centers_[i][0]), \n",
    "        math.ceil(clusters.cluster_centers_[i][1]),\n",
    "    math.ceil(clusters.cluster_centers_[i][2])))\n",
    "plot.show()\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de164a2",
   "metadata": {},
   "source": [
    "On doit obtenir : \n",
    "\n",
    "![test](images/Markdown/BarKmeans.png)\n",
    "\n",
    "```\n",
    "2.0494699478149414\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c922b",
   "metadata": {},
   "source": [
    "On test maintenant avec l'algorithme **MiniBatchKMeans**. Celui-ci est plus rapide que Kmeans en théorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d06450-c399-40d3-8efc-84e48d0e8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "imgfile = Image.open(\"images/flowers/daisies_00046.jpg\")\n",
    "n_clusters = 4\n",
    "numarray = numpy.array(imgfile.getdata(), numpy.uint8)\n",
    "clusters = MiniBatchKMeans(n_clusters)\n",
    "clusters.fit(numarray)\n",
    "npbins = numpy.arange(0, n_clusters+1)\n",
    "histogram = numpy.histogram(clusters.labels_, bins=npbins)\n",
    "labels = numpy.unique(clusters.labels_)\n",
    "index1 = {}\n",
    "for i,element in enumerate(histogram[0]):\n",
    "    index1[element] = i\n",
    "#print(index1)\n",
    "histoSort = sorted(histogram[0], reverse=True)\n",
    "#print(histoSort)\n",
    "index2 = {}\n",
    "for i,element in enumerate(histoSort):\n",
    "    index2[i] = element\n",
    "#print(index2)\n",
    "barlist = plot.bar(labels, histoSort)\n",
    "colors = []\n",
    "colorsDec = []\n",
    "for k in range(n_clusters):\n",
    "    i = index1[index2[k]]\n",
    "    colors.append('#%02x%02x%02x' % (\n",
    "    math.ceil(clusters.cluster_centers_[i][0]), #RGB normalement 0:R 1:G 2:B\n",
    "        math.ceil(clusters.cluster_centers_[i][1]),\n",
    "    math.ceil(clusters.cluster_centers_[i][2])))\n",
    "    \n",
    "    colorsDec.append([math.ceil(clusters.cluster_centers_[i][0]), #RGB normalement 0:R 1:G 2:B\n",
    "        math.ceil(clusters.cluster_centers_[i][1]),\n",
    "    math.ceil(clusters.cluster_centers_[i][2])])\n",
    "    \n",
    "    barlist[k].set_color('#%02x%02x%02x' % (\n",
    "    math.ceil(clusters.cluster_centers_[i][0]), \n",
    "        math.ceil(clusters.cluster_centers_[i][1]),\n",
    "    math.ceil(clusters.cluster_centers_[i][2])))\n",
    "\n",
    "plot.show()\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7e82b",
   "metadata": {},
   "source": [
    "On doit obtenir : \n",
    "\n",
    "![test](images/Markdown/BarMiniBatchKmeans.png)\n",
    "\n",
    "```\n",
    "0.4316437244415283\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00633926",
   "metadata": {},
   "source": [
    "Ici on remarque bien que l'algorithme MiniBatchKMeans va beaucoup plus vite que l'algorithme des KMeans bien qu'il soit moins précis. Nous décidons de l'utiliser tout de même car nous ne pouvons pas nous permettre de prendre trop de temps pour traiter les 700 images !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ef649",
   "metadata": {},
   "source": [
    "On recupere un base de données comprenant un certain nombre de couleurs permetant d'avoir des réferences. Comme cette base de données posséde trop de variations de couleurs, nous enlevons une partie des couleurs secondaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondataColor = json.load(open(\"colours_rgb_shades.json\"))\n",
    "array = []\n",
    "\n",
    "for data in jsondataColor:\n",
    "    array.append([data[\"Color Name\"], data[\"Credits\"], data[\"R;G;B Dec\"]])\n",
    "#On crée notre dataframe    \n",
    "dataframe = pd.DataFrame(array, columns=[\"Color Name\", \"Credits\", \"R;G;B Dec\"])\n",
    "dataframe = dataframe.astype(\n",
    "    dtype={\"Color Name\": \"<U200\", \"Credits\": \"<U200\", \"R;G;B Dec\": \"<U200\"}\n",
    ")\n",
    "#On ne conserve que les couleurs principales.\n",
    "selectColor = dataframe.loc[(dataframe[\"Credits\"] == \"N,V,X\")  | (dataframe[\"Credits\"] == \"N,X\")]\n",
    "print(selectColor)\n",
    "\n",
    "\n",
    "\n",
    "selectColor.to_json (r'dataSelectColor.json',orient = \"index\",indent = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563fc1f",
   "metadata": {},
   "source": [
    "On doit obtenir : \n",
    "\n",
    "```\n",
    "    Color Name Credits    R;G;B Dec\n",
    "10       black   N,V,X        0;0;0\n",
    "215       blue   N,V,X      0;0;255\n",
    "222       cyan     N,X    0;255;255\n",
    "342      green     N,X      0;255;0\n",
    "471        red   N,V,X      255;0;0\n",
    "514    magenta     N,X    255;0;255\n",
    "595      white   N,V,X  255;255;255\n",
    "633     yellow   N,V,X    255;255;0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef3a3b",
   "metadata": {},
   "source": [
    "Nous obtenons des couleurs de référence pour permettre d'approximer les couleurs de nos images. \n",
    "   \n",
    "Le code suivant récupere ces couleurs de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451eb05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['black', [0, 0, 0]], ['blue', [0, 0, 255]], ['cyan', [0, 255, 255]], ['green', [0, 255, 0]], ['red', [255, 0, 0]], ['magenta', [255, 0, 255]], ['white', [255, 255, 255]], ['yellow', [255, 255, 0]]]\n"
     ]
    }
   ],
   "source": [
    "with open('dataSelectColor.json') as mon_fichier:\n",
    "    data = json.load(mon_fichier)\n",
    "colorList = [] \n",
    "for key in data :\n",
    "    colorList.append([data[key]['Color Name'],data[key]['R;G;B Dec'].split(\";\")])\n",
    "#modilfication type RGB \n",
    "for element in colorList :\n",
    "    element[1][0] = int(element[1][0])\n",
    "    element[1][1] = int(element[1][1])\n",
    "    element[1][2] = int(element[1][2])\n",
    "\n",
    "ListeCouleurs = colorList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b5937",
   "metadata": {},
   "source": [
    "On utilise les couleurs de réference dans notre detection de couleurs. Le code suivant démontre la possibilité de récupérer les couleurs dominantes d'une image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colorsDec)\n",
    "\n",
    "data = {}\n",
    "for i in range(0,4) : \n",
    "    R = colorsDec[i][0] #colorsDec est les 4 couleurs dominantes d'une image.\n",
    "    G = colorsDec[i][1]\n",
    "    B = colorsDec[i][2]\n",
    "\n",
    "\n",
    "    #ListeCouleurs = [[255,255,255],[0,0,255],[0,0,125],[0,255,0],[255,0,0],[0,0,0]]\n",
    "    normeMin = 255\n",
    "    couleursRef = []\n",
    "    #on fait la norme 2 sur les 3 canaux (R,G,B)\n",
    "    for couleurs in ListeCouleurs :\n",
    "        norme = (abs(couleurs[1][0]-R) + abs(couleurs[1][1]-G) + abs(couleurs[1][2]-B))/3\n",
    "        if norme <= normeMin : \n",
    "            couleursRef = couleurs\n",
    "            normeMin = norme\n",
    "    data[\"couleur \" + str(i)] = couleursRef\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a27b6",
   "metadata": {},
   "source": [
    "Ceci est un test de modification d'un fichier JSON. Ce code est passé en Markdown pour ne pas qu'il soit relancé et déteriore le data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67de614",
   "metadata": {},
   "source": [
    "```python  \n",
    "filename = 'data.json'\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    data[0]['couleur 1'] = 12\n",
    "\n",
    "os.remove(filename)\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320a64d",
   "metadata": {},
   "source": [
    "On passe maintenant à l'application de l'exemple au projet. ce code permet de trouver les 4 couleurs dominantes parmis un set de couleurs de référence, de toute les photos de notre dataset. Ce code est passé en Markdown pour ne pas qu'il soit relancé et déteriore le data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052f7ce",
   "metadata": {},
   "source": [
    "```python  \n",
    "filename = 'data.json'\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "#recuperation des images une par une\n",
    "print(len(data))\n",
    "for index in range (len(data )):\n",
    "    path = \"images/flowers/\" + data[index]['name'] + \"_\" + data[index]['id_picture'] + \".jpg\"\n",
    "    \n",
    "    print(path)\n",
    "    #MiniBatchKmeans\n",
    "\n",
    "    imgfile = Image.open(path)\n",
    "    n_clusters = 4\n",
    "    numarray = numpy.array(imgfile.getdata(), numpy.uint8)\n",
    "    clusters = MiniBatchKMeans(n_clusters)\n",
    "    clusters.fit(numarray)\n",
    "    npbins = numpy.arange(0, n_clusters+1)\n",
    "    histogram = numpy.histogram(clusters.labels_, bins=npbins)\n",
    "    labels = numpy.unique(clusters.labels_)\n",
    "    index1 = {}\n",
    "    for i,element in enumerate(histogram[0]):\n",
    "        index1[element] = i\n",
    "\n",
    "    histoSort = sorted(histogram[0], reverse=True)\n",
    "\n",
    "    index2 = {}\n",
    "    for i,element in enumerate(histoSort):\n",
    "        index2[i] = element\n",
    "\n",
    "    barlist = plot.bar(labels, histoSort)\n",
    "    colors = []\n",
    "    colorsDec = []\n",
    "    for k in range(n_clusters):\n",
    "        i = index1[index2[k]]\n",
    "        colors.append('#%02x%02x%02x' % (\n",
    "        math.ceil(clusters.cluster_centers_[i][0]), #RGB normalement 0:R 1:G 2:B\n",
    "            math.ceil(clusters.cluster_centers_[i][1]),\n",
    "        math.ceil(clusters.cluster_centers_[i][2])))\n",
    "\n",
    "        colorsDec.append([math.ceil(clusters.cluster_centers_[i][0]), #RGB normalement 0:R 1:G 2:B\n",
    "            math.ceil(clusters.cluster_centers_[i][1]),\n",
    "        math.ceil(clusters.cluster_centers_[i][2])])\n",
    "\n",
    "        barlist[k].set_color('#%02x%02x%02x' % (\n",
    "        math.ceil(clusters.cluster_centers_[i][0]), \n",
    "            math.ceil(clusters.cluster_centers_[i][1]),\n",
    "        math.ceil(clusters.cluster_centers_[i][2])))\n",
    "        \n",
    "#comparaison des couleurs :        \n",
    "\n",
    "    dataCouleurs = {}\n",
    "    for i in range(0,4) : \n",
    "        R = colorsDec[i][0]\n",
    "        G = colorsDec[i][1]\n",
    "        B = colorsDec[i][2]\n",
    "\n",
    "\n",
    "        #ListeCouleurs = [[255,255,255],[0,0,255],[0,0,125],[0,255,0],[255,0,0],[0,0,0]]\n",
    "        normeMin = 255\n",
    "        couleursRef = []\n",
    "        #on fait la norme 2 sur les 3 canaux (R,G,B)\n",
    "        for couleurs in ListeCouleurs :\n",
    "            norme = (abs(couleurs[1][0]-R) + abs(couleurs[1][1]-G) + abs(couleurs[1][2]-B))/3\n",
    "            if norme <= normeMin : \n",
    "                couleursRef = couleurs\n",
    "                normeMin = norme\n",
    "        data[index]['couleur ' +  str(i)] = couleursRef\n",
    "\n",
    "\n",
    "os.remove(filename)\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd325f",
   "metadata": {},
   "source": [
    "Le but est maintenant de créer l'algorithme de visualisation des données permettant de voir le nombre d'image par couleur, et le nombre d'image paysage, carré et portrait. Pour cela on utilise un dataframe pour chaque colonne ainsi que *.value_count()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b544495",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.json'\n",
    "arrayVisu = []\n",
    "#on ouvre le fichier data.json en lecture seule\n",
    "with open(filename, 'r') as f:\n",
    "    dataVisu = json.load(f)\n",
    "    \n",
    "for data in dataVisu:\n",
    "    arrayVisu.append([data[\"name\"],data[\"couleur 0\"], data[\"couleur 1\"], \n",
    "                  data[\"couleur 2\"], data[\"couleur 3\"], data[\"orientation\"]])\n",
    "\n",
    "dataframeVisu = pd.DataFrame(arrayVisu, columns=[\"name\", \"couleur 0\",\"couleur 1\",\"couleur 2\",\"couleur 3\", \"orientation\"])\n",
    "dataframeVisu = dataframeVisu.astype(\n",
    "    dtype={\"name\": \"<U200\", \"couleur 0\": \"<U200\", \"couleur 1\": \"<U200\",\"couleur 2\": \"<U200\",\n",
    "           \"couleur 3\": \"<U200\",\"orientation\": \"<U200\"}\n",
    ")\n",
    "countName = dataframeVisu['name'].value_counts()\n",
    "countOrientation = dataframeVisu['orientation'].value_counts()\n",
    "couleur0 = dataframeVisu['couleur 0'].value_counts()\n",
    "couleur1 = dataframeVisu['couleur 1'].value_counts()\n",
    "couleur2 = dataframeVisu['couleur 2'].value_counts()\n",
    "couleur3 = dataframeVisu['couleur 3'].value_counts()\n",
    "\n",
    "#affichage de l'histogramme\n",
    "axes = countOrientation.plot.bar(rot=90, subplots=True)\n",
    "\n",
    "print(countOrientation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d00ff",
   "metadata": {},
   "source": [
    "On doit obtenir : \n",
    "\n",
    "```\n",
    "paysage     504\n",
    "portrait    145\n",
    "carre        84\n",
    "Name: orientation, dtype: int64\n",
    "```\n",
    "\n",
    "\n",
    "![test](images/Markdown/BarOrientation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fec334",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = countName.plot.bar(rot=90,subplots=True)\n",
    "print(countName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676ad1c",
   "metadata": {},
   "source": [
    "On doit obtenir : \n",
    "\n",
    "```\n",
    "daisies          83\n",
    "lilies           81\n",
    "gardenias        77\n",
    "peonies          75\n",
    "bougainvillea    74\n",
    "garden_roses     74\n",
    "hibiscus         74\n",
    "tulip            71\n",
    "orchids          64\n",
    "hydrangeas       60\n",
    "Name: name, dtype: int64\n",
    "```\n",
    "\n",
    "\n",
    "![test](images/Markdown/BarFleurs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace41f44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plot.subplots(nrows=2, ncols=2, figsize=(15,15))\n",
    "#Creation des subplots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "barlist0 = couleur0.plot(kind='bar',title=\"couleur0\", ax=axes[0,0])\n",
    "barlist1 =couleur1.plot(kind='bar',title=\"couleur1\", ax=axes[0,1])\n",
    "barlist2 = couleur2.plot(kind='bar',title=\"couleur2\", ax=axes[1,0])\n",
    "barlist3 = couleur3.plot(kind='bar',title=\"couleur3\", ax=axes[1,1])\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbbad3",
   "metadata": {},
   "source": [
    "On doit obtenir :  \n",
    "\n",
    "![test](images/Markdown/BarCouleurs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bedb08",
   "metadata": {},
   "source": [
    "## Analyse de données et Système de recommandation  \n",
    "  \n",
    "Dans cette partie nous allons utiliser un *decision tree classifiers* pour recommander des photos à partir du classifier entrainé grâce à 50% de nos images. Nous testons ensuite les prédictions grâce aux 50% restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a40ba7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display \n",
    "\n",
    "filename = 'data.json'\n",
    "dataTot = []\n",
    "dataPredict = []\n",
    "with open(filename, 'r') as f:\n",
    "    dataJson = json.load(f)\n",
    "    \n",
    "for i,data in enumerate(dataJson):\n",
    "        dataTot.append([data[\"name\"],data[\"couleur 0\"][0], data[\"couleur 1\"][0], \n",
    "                  data[\"couleur 2\"][0], data[\"couleur 3\"][0], data[\"orientation\"]])\n",
    "# On s'assûre que tous les types de fleur, et couleurs et orientation sont passés aux classificateurs\n",
    "# Pour qu'il ne plante pas\n",
    "dataTraining = [['bougainvillea','magenta','magenta','magenta','magenta','portrait'],\n",
    "                ['daisies','black','black','black','black','carre'],\n",
    "                ['lilies','white','white','white','white','paysage'],\n",
    "                ['gardenias','red','red','red','red','paysage'],\n",
    "                ['peonies','yellow','yellow','yellow','yellow','paysage'],\n",
    "                ['garden_roses','green','green','green','green','paysage'],\n",
    "                ['hibiscus','blue','blue','blue','blue','paysage'],\n",
    "                ['tulip','cyan','cyan','cyan','cyan','paysage'],\n",
    "                ['orchids','white','white','white','white','paysage'],\n",
    "                ['hydrangeas','black','black','black','black','paysage']]\n",
    "\n",
    "for i in range(len(dataTot)):\n",
    "    if i%2 == 0:\n",
    "        dataTraining.append(dataTot[i])\n",
    "    else:\n",
    "        dataPredict.append(dataTot[i])\n",
    "\n",
    "result = ['Favorite','Favorite','Favorite','Favorite','Favorite','Favorite','Favorite','Favorite','Favorite','Favorite']    \n",
    "for i in range(len(dataTraining)):\n",
    "    if i <= 46: #On veut aimer seulement les bougainvillea\n",
    "        if i >= 10:\n",
    "            result.append('Favorite')\n",
    "    else:\n",
    "        result.append('NotFavorite')\n",
    "\n",
    "\n",
    "#creating dataframes\n",
    "dataframe = pd.DataFrame(dataTraining, columns=['name', 'couleur 0', 'couleur 1', 'couleur 2', 'couleur 3', 'orientation'])\n",
    "resultframe = pd.DataFrame(result, columns=['favorite'])\n",
    "predictframe = pd.DataFrame(dataPredict, columns=['name', 'couleur 0', 'couleur 1', 'couleur 2', 'couleur 3', 'orientation'])\n",
    "#generating numerical labels\n",
    "le1 = LabelEncoder()\n",
    "dataframe['name'] = le1.fit_transform(dataframe['name'])\n",
    "predictframe['name'] = le1.fit_transform(predictframe['name'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "dataframe['couleur 0'] = le2.fit_transform(dataframe['couleur 0'])\n",
    "predictframe['couleur 0'] = le2.fit_transform(predictframe['couleur 0'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "dataframe['couleur 1'] = le3.fit_transform(dataframe['couleur 1'])\n",
    "predictframe['couleur 1'] = le3.fit_transform(predictframe['couleur 1'])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "dataframe['couleur 2'] = le4.fit_transform(dataframe['couleur 2'])\n",
    "predictframe['couleur 2'] = le4.fit_transform(predictframe['couleur 2'])\n",
    "\n",
    "le5 = LabelEncoder()\n",
    "dataframe['couleur 3'] = le5.fit_transform(dataframe['couleur 3'])\n",
    "predictframe['couleur 3'] = le5.fit_transform(predictframe['couleur 3'])\n",
    "\n",
    "le6 = LabelEncoder()\n",
    "dataframe['orientation'] = le6.fit_transform(dataframe['orientation'])\n",
    "predictframe['orientation'] = le6.fit_transform(predictframe['orientation'])\n",
    "\n",
    "le7 = LabelEncoder()\n",
    "resultframe['favorite'] = le7.fit_transform(resultframe['favorite'])\n",
    "\n",
    "#Use of decision tree classifiers\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_depth=6,\n",
    "                  random_state=0,)\n",
    "rfc = rfc.fit(dataframe, resultframe.values.ravel())\n",
    "\n",
    "for i in range(10):\n",
    "        dot_data = tree.export_graphviz(rfc.estimators_[i], out_file=None,\n",
    "        feature_names=dataframe.columns,\n",
    "        filled=True, rounded=True,\n",
    "        class_names =\n",
    "         le7.inverse_transform(\n",
    "           resultframe.favorite.unique())\n",
    "        ) \n",
    "        graph = graphviz.Source(dot_data) \n",
    "        pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        img = Image(pydot_graph.create_png())\n",
    "        display(img)\n",
    "        \n",
    "prediction1 = rfc.predict([\n",
    "        [le1.transform(['daisies'])[0], le2.transform(['white'])[0],\n",
    "         le3.transform(['black'])[0], le4.transform(['white'])[0], le5.transform(['yellow'])[0], le6.transform(['portrait'])[0]]])\n",
    "print(\"Daisy: \" + str(le7.inverse_transform(prediction1)))\n",
    "prediction2 = rfc.predict([\n",
    "        [le1.transform(['bougainvillea'])[0], le2.transform(['white'])[0],\n",
    "         le3.transform(['black'])[0], le4.transform(['white'])[0], le5.transform(['yellow'])[0], le6.transform(['portrait'])[0]]])\n",
    "print(\"Bougainvillea: \" + str(le7.inverse_transform(prediction2)))\n",
    "prediction3 = rfc.predict(predictframe)\n",
    "print(le7.inverse_transform(prediction3))\n",
    "print(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc7216",
   "metadata": {},
   "source": [
    "On doit obtenir : \n",
    "\n",
    "![test](images/Markdown/predict1.png)\n",
    "![test](images/Markdown/predict2.png)\n",
    "![test](images/Markdown/predict3.png)\n",
    "![test](images/Markdown/predict4.png)\n",
    "![test](images/Markdown/predict5.png)\n",
    "![test](images/Markdown/predict6.png)\n",
    "![test](images/Markdown/predict7.png)\n",
    "![test](images/Markdown/predict8.png)\n",
    "![test](images/Markdown/predict9.png)\n",
    "![test](images/Markdown/predict10.png)\n",
    "\n",
    "```\n",
    "Daisy: ['NotFavorite']\n",
    "Bougainvillea: ['Favorite']\n",
    "['Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite'\n",
    " 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite'\n",
    " 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite'\n",
    " 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite'\n",
    " 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite'\n",
    " 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite' 'Favorite'\n",
    " 'Favorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite'\n",
    " 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite' 'NotFavorite']\n",
    "[0.72327008 0.08734273 0.05439743 0.06698752 0.04412897 0.02387326]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa9eaf",
   "metadata": {},
   "source": [
    "On observe bien que les photos likées sont des Bougainvillea (car en premiere dans la liste). Cela est cohérant car nous avons aimé uniquement les photos paires des Bougainvillea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
